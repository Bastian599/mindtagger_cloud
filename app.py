# app.py ‚Äî Jira Stichwort-Zuordnung PRO v4.2 (Cloud)
# New in 4.2:
# - Robust client storage: try extra_streamlit_components.CookieManager,
#   fall back to browser localStorage via streamlit_js_eval if the component cannot load.
# - Unique keys for all cookie ops; warmup + rerun only when CookieManager is active.

import os, re, io, time, json, base64
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, date, time as dtime, timedelta, timezone

import requests
import pandas as pd
import streamlit as st
from sqlalchemy import create_engine, text
from cryptography.fernet import Fernet

st.set_page_config(page_title="Jira Stichwort-Zuordnung PRO v4.2 ‚Äî Cloud", layout="wide")

# ----------------------------- Secrets & Defaults -----------------------------
def _sec(name: str, default: str = "") -> str:
    try: return st.secrets.get(name, default)  # type: ignore[attr-defined]
    except Exception: return os.getenv(name, default)

DB_URL = _sec("DATABASE_URL", "sqlite:///./creds.db")
FERNET_KEY = _sec("FERNET_KEY", "")
if not FERNET_KEY:
    st.error("Admin-Hinweis: FERNET_KEY fehlt in Secrets. Bitte in Streamlit Secrets setzen.")
    st.stop()

engine = create_engine(DB_URL, pool_pre_ping=True)
cipher = Fernet(FERNET_KEY.encode() if isinstance(FERNET_KEY, str) else FERNET_KEY)

# ----------------------------- Client storage (Cookie or LocalStorage) --------
STORAGE_MODE = None  # "cookie" | "localstorage" | None
cookie = None
local_get = local_set = local_remove = None

try:
    import extra_streamlit_components as stx  # type: ignore
    cookie = stx.CookieManager(key="cookie_mgr_v2")
    STORAGE_MODE = "cookie"
except Exception:
    try:
        from streamlit_js_eval import get_local_storage, set_local_storage, remove_local_storage  # type: ignore
        local_get, local_set, local_remove = get_local_storage, set_local_storage, remove_local_storage
        STORAGE_MODE = "localstorage"
    except Exception:
        STORAGE_MODE = None

# Warmup for CookieManager only
if STORAGE_MODE == "cookie" and "cookies_warmed" not in st.session_state:
    try:
        cookie.get_all(key="warmup_all")
    except Exception:
        pass
    st.session_state["cookies_warmed"] = True
    st.rerun()

def storage_get_user() -> Optional[str]:
    try:
        if STORAGE_MODE == "cookie":
            cookies = cookie.get_all(key="read_all") or {}
            return cookies.get("jira_user")
        elif STORAGE_MODE == "localstorage":
            return local_get("jira_user")
    except Exception:
        return None
    return None

def storage_set_user(account_id: str):
    try:
        if STORAGE_MODE == "cookie":
            exp = (datetime.now(timezone.utc) + timedelta(days=180)).strftime("%a, %d %b %Y %H:%M:%S GMT")
            cookie.set("jira_user", account_id, expires=exp, key="set_jira_user")
        elif STORAGE_MODE == "localstorage":
            local_set("jira_user", account_id)
    except Exception:
        pass

def storage_del_user():
    try:
        if STORAGE_MODE == "cookie":
            cookie.delete("jira_user", key="del_jira_user")
        elif STORAGE_MODE == "localstorage":
            local_remove("jira_user")
    except Exception:
        pass

# ----------------------------- Helpers -----------------------------
P_PATTERN = re.compile(r"^P\d{6}$")
def is_p_label(label: str) -> bool: return bool(P_PATTERN.match(label or ""))
def extract_p_label(labels: List[str]) -> Optional[str]:
    for l in labels or []:
        if is_p_label(l): return l
    return None
def hide_sidebar_css():
    st.markdown("""<style>[data-testid="stSidebar"]{display:none!important}.block-container{padding-top:1rem}</style>""", unsafe_allow_html=True)
def to_started_iso(d: date, t: dtime) -> str:
    local_tz = datetime.now().astimezone().tzinfo
    return datetime.combine(d, t).replace(tzinfo=local_tz).strftime("%Y-%m-%dT%H:%M:%S.000%z")
def ensure_15min(seconds: int) -> bool: return seconds % 900 == 0 and seconds > 0
def adf_comment(text: str) -> Dict[str, Any]:
    txt=(text or "").strip() or "Zeiterfassung √ºber Stichwort-Tool"
    return {"type":"doc","version":1,"content":[{"type":"paragraph","content":[{"type":"text","text":txt}]}]}
def fill_template(tpl: str, p: str, key: str, summary: str, d: date) -> str:
    if not tpl: return ""
    return tpl.replace("{P}", p or "").replace("{ISSUE}", key or "").replace("{SUMMARY}", summary or "").replace("{DATE}", d.isoformat())
def week_bounds_from(d: date) -> Tuple[date,date]:
    monday = d - timedelta(days=d.weekday())
    return monday, monday+timedelta(days=7)

# ----------------------------- Jira Client (Basic) ------------------------
class JiraError(Exception): pass
def normalize_base_url(url: str) -> str: url=(url or "").strip(); return url[:-1] if url.endswith("/") else url

class JiraClientBasic:
    def __init__(self, base_url, email, api_token, timeout=30):
        self.base_url=normalize_base_url(base_url); self.timeout=timeout
        self.s=requests.Session(); self.s.auth=(email, api_token)
        self.s.headers.update({"Accept":"application/json","Content-Type":"application/json"})
    def _req(self, method, path, params=None, data=None, retries=3, return_headers=False):
        url=f"{self.base_url}{path}"
        for attempt in range(retries):
            r=self.s.request(method,url,params=params,data=data,timeout=self.timeout)
            if return_headers: return r
            if r.status_code in (429,502,503,504):
                time.sleep(1.5*(attempt+1)); continue
            if r.status_code>=400:
                try: detail=r.json()
                except Exception: detail=r.text
                raise JiraError(f"HTTP {r.status_code} f√ºr {path}: {detail}")
            try: return r.json()
            except Exception: return None
        raise JiraError(f"Failed after retries: {method} {path}")
    def get_myself(self): return self._req("GET","/rest/api/3/myself")
    def list_projects(self, only_led_by: Optional[str] = None):
        start_at=0; max_results=50; out=[]
        while True:
            d=self._req("GET","/rest/api/3/project/search", params={"expand":"lead","startAt":start_at,"maxResults":max_results})
            for p in d.get("values",[]):
                if only_led_by:
                    if (p.get("lead") or {}).get("accountId")==only_led_by: out.append(p)
                else: out.append(p)
            if start_at+max_results>=d.get("total",0): break
            start_at+=max_results
        return out
    def search_issues(self, jql, fields, batch_size=100):
        start_at=0; out=[]
        while True:
            d=self._req("POST","/rest/api/3/search", data=json.dumps({"jql":jql,"startAt":start_at,"maxResults":batch_size,"fields":fields}))
            out.extend(d.get("issues",[])); 
            if start_at+batch_size>=d.get("total",0): break
            start_at+=batch_size
        return out
    def update_issue_labels(self, issue_key, new_labels):
        self._req("PUT", f"/rest/api/3/issue/{issue_key}", data=json.dumps({"fields":{"labels":new_labels}}))
    def add_worklog(self, issue_key, started_iso, seconds, comment_text):
        d=self._req("POST", f"/rest/api/3/issue/{issue_key}/worklog", data=json.dumps({"started":started_iso,"timeSpentSeconds":seconds,"comment":adf_comment(comment_text)}))
        return d.get("id")
    def list_worklogs(self, issue_key):
        out=[]; startAt=0; maxResults=100
        while True:
            d=self._req("GET", f"/rest/api/3/issue/{issue_key}/worklog", params={"startAt":startAt,"maxResults":maxResults})
            out.extend(d.get("worklogs",[]))
            if startAt+maxResults>=d.get("total",len(out)): break
            startAt+=maxResults
        return {"worklogs": out}
    def delete_worklog(self, issue_key, worklog_id):
        self._req("DELETE", f"/rest/api/3/issue/{issue_key}/worklog/{worklog_id}")
    def probe_headers(self):
        r=self._req("GET","/rest/api/3/myself", return_headers=True)
        return dict(r.headers), r.status_code

# ----------------------------- App Header -----------------------------
st.title("Jira Stichwort-Zuordnung ‚Äî PRO v4.2 (Cloud)")
st.caption("Per-User-Login (Cookie/LocalStorage + DB) ‚Ä¢ Timesheet ‚Ä¢ Health-Check+ ‚Ä¢ Multi-Tab ‚Ä¢ Multi-Projekt")
if STORAGE_MODE == "localstorage":
    st.info("Hinweis: Fallback auf Browser LocalStorage aktiv (Cookie-Komponente nicht verf√ºgbar).")

for k in ["jira","myself","site_url","sidebar_collapsed","timesheet","undo","projects_cache","own_only_prev"]: 
    st.session_state.setdefault(k, None)

# ----------------------------- Auto-Connect via client storage ------------------
if not st.session_state.get("jira"):
    aid = storage_get_user()
    if aid:
        try:
            # DB ops
            with engine.begin() as con:
                row = con.execute(text("SELECT jira_base_url, email, enc_token FROM user_credentials WHERE account_id=:aid"), {"aid": aid}).fetchone()
            if row:
                base_url, email, enc_enc = row[0], row[1], row[2]
                api_token = cipher.decrypt(base64.b64decode(enc_enc.encode())).decode()
                jira = JiraClientBasic(base_url, email, api_token); me = jira.get_myself()
                st.session_state.jira, st.session_state.myself, st.session_state.site_url = jira, me, base_url
                st.session_state.sidebar_collapsed=True
        except Exception as e:
            st.sidebar.warning(f"Auto-Login fehlgeschlagen: {e}")

# ----------------------------- Login Sidebar -----------------------------
st.sidebar.header("Anmeldung (pro Benutzer)")
base_url  = st.sidebar.text_input("Jira Base-URL", value="")
email     = st.sidebar.text_input("E-Mail", value="")
api_token = st.sidebar.text_input("API Token", type="password", value="")
remember  = st.sidebar.checkbox("Auf diesem Ger√§t merken", value=True)
colL, colR = st.sidebar.columns(2)
connect = colL.button("Verbinden")
logout  = colR.button("Logout")

# Device/Credential controls
colA, colB = st.sidebar.columns(2)
forget_device = colA.button("Dieses Ger√§t vergessen")
delete_saved  = colB.button("Gespeicherte Daten l√∂schen")

if forget_device:
    storage_del_user()
    st.sidebar.success("Ger√§te-Speicherung gel√∂scht.")

if delete_saved:
    try:
        if st.session_state.get("myself"):
            with engine.begin() as con:
                con.execute(text("DELETE FROM user_credentials WHERE account_id=:aid"), {"aid": st.session_state["myself"]["accountId"]})
            st.sidebar.success("Gespeicherte Zugangsdaten gel√∂scht.")
        else:
            aid = storage_get_user()
            if aid:
                with engine.begin() as con:
                    con.execute(text("DELETE FROM user_credentials WHERE account_id=:aid"), {"aid": aid})
                st.sidebar.success("Gespeicherte Zugangsdaten gel√∂scht.")
    except Exception as e:
        st.sidebar.error(f"Konnte nicht l√∂schen: {e}")

if connect:
    try:
        jira = JiraClientBasic(base_url, email, api_token); me = jira.get_myself()
        st.session_state.jira=jira; st.session_state.myself=me; st.session_state.site_url=base_url
        st.session_state.sidebar_collapsed=True
        if remember:
            # save creds
            enc = base64.b64encode(cipher.encrypt(api_token.encode())).decode()
            with engine.begin() as con:
                con.execute(text("""
                    INSERT INTO user_credentials (account_id, jira_base_url, email, enc_token, updated_at)
                    VALUES (:aid,:url,:mail,:tok, CURRENT_TIMESTAMP)
                    ON CONFLICT (account_id) DO UPDATE SET
                      jira_base_url=EXCLUDED.jira_base_url,
                      email=EXCLUDED.email,
                      enc_token=EXCLUDED.enc_token,
                      updated_at=CURRENT_TIMESTAMP
                """), {"aid": me["accountId"], "url": base_url, "mail": email, "tok": enc})
            storage_set_user(me["accountId"])
        st.success(f"Verbunden als: {me.get('displayName')}")
    except Exception as e:
        st.sidebar.error(f"Verbindungsfehler: {e}")

if logout:
    storage_del_user()
    for k in ["jira","myself","site_url","projects_cache","own_only_prev"]:
        st.session_state[k]=None
    st.rerun()

# --- Erst hier stoppen, falls nicht verbunden ---
if not st.session_state.get("jira"):
    st.stop()
# ------------------------------------------------

# Sidebar collapse
def hide_sidebar_css():
    st.markdown("""<style>[data-testid="stSidebar"]{display:none!important}.block-container{padding-top:1rem}</style>""", unsafe_allow_html=True)
if st.session_state.get("sidebar_collapsed", False):
    hide_sidebar_css()
    if st.button("‚öôÔ∏è Einstellungen anzeigen"): st.session_state.sidebar_collapsed=False; st.rerun()
else:
    st.sidebar.button("‚Ü©Ô∏é Sidebar einklappen", on_click=lambda: (st.session_state.update({"sidebar_collapsed": True}), st.rerun()))

jira=st.session_state.jira; me=st.session_state.myself; site_url=st.session_state.site_url

# ----------------------------- Projekte ----------------------------
def _invalidate_projects():
    st.session_state.projects_cache=None

own_only = st.toggle("Nur Projekte, bei denen ich Lead bin", value=bool(st.session_state.get("own_only_prev") or False), key="own_only_toggle", on_change=_invalidate_projects)
if st.session_state.own_only_prev is None or st.session_state.own_only_prev != own_only:
    st.session_state.projects_cache=None
st.session_state.own_only_prev = own_only

with st.spinner("Lade Projekte‚Ä¶"):
    if not st.session_state.get("projects_cache"):
        projs = jira.list_projects(me.get("accountId") if own_only else None)
        if own_only and not projs:
            st.info("Keine Projekte mit dir als Lead gefunden ‚Äì zeige alle Projekte.")
            projs = jira.list_projects(None)
        st.session_state.projects_cache = sorted(projs, key=lambda p: p.get("key",""))

projects = st.session_state.projects_cache or []
proj_labels=[f"{p.get('key')} ‚Äî {p.get('name')}" for p in projects]
proj_key_by_label={f"{p.get('key')} ‚Äî {p.get('name')}": p.get("key") for p in projects}

st.toggle("Multi-Projekt-Modus", value=False, key="multi_proj", help="Mehrere Projekte gleichzeitig anzeigen/bearbeiten")
if st.session_state.multi_proj and projects:
    selected_labels = st.multiselect("Projekte ausw√§hlen", proj_labels, default=proj_labels[:1], key="proj_multi")
    selected_keys = [proj_key_by_label[l] for l in selected_labels]
else:
    selected_label = st.selectbox("Projekt ausw√§hlen", proj_labels, index=0 if proj_labels else None, key="proj_single")
    selected_keys = [proj_key_by_label[selected_label]] if proj_labels else []

st.markdown("‚Äî")

# ----------------------------- Daten laden -------------------------
@st.cache_data(ttl=120, show_spinner=False)
def fetch_issues_df(_jira_client, project_keys: List[str], site_url: str) -> pd.DataFrame:
    if isinstance(project_keys, str): project_keys=[project_keys]
    if not project_keys: 
        return pd.DataFrame(columns=["Project","Key","Ticket","Summary","Status","P_Label_Aktuell","Alle_Labels"])
    quoted = ",".join([f'"{k}"' for k in project_keys])
    jql = f'project in ({quoted}) AND statusCategory != Done ORDER BY created DESC'
    fields = ["summary","status","labels","project"]
    issues = _jira_client.search_issues(jql, fields)
    rows=[]
    for it in issues:
        k=it.get("key"); f=it.get("fields",{})
        proj=(f.get("project") or {}).get("key","")
        summary=f.get("summary",""); status=(f.get("status") or {}).get("name",""); labels=f.get("labels") or []
        p_label=extract_p_label(labels); link=f"{site_url}/browse/{k}" if site_url else ""
        rows.append({"Project":proj,"Key":k,"Ticket":link,"Summary":summary,"Status":status,"P_Label_Aktuell":p_label or "", "Alle_Labels":", ".join(labels) if labels else ""})
    return pd.DataFrame(rows)

def refresh_after_update():
    fetch_issues_df.clear(); st.experimental_set_query_params(_=str(time.time())); st.rerun()

df = fetch_issues_df(jira, selected_keys, site_url)

# ----------------------------- Tabs -------------------------------
tab_overview, tab_plabel, tab_worklog, tab_csv, tab_reports, tab_timesheet, tab_health = st.tabs(
    ["üìã √úbersicht","üè∑Ô∏è P-Labels","‚è±Ô∏è Worklog (Einzeln)","üì• CSV-Import","üìä Reports & Export","üóìÔ∏è Timesheet","ü©∫ Health-Check+"]
)

# ----------------------------- √úbersicht --------------------------
from collections import Counter
with tab_overview:
    st.subheader("√úbersicht & Filter")
    colf1,colf2,colf3,colf4=st.columns([2,1,1,1])
    q=colf1.text_input("Suche (Key/Summary)", "", key="ov_q")
    status_vals=sorted(df["Status"].unique().tolist()) if not df.empty else []
    chosen_status=colf2.multiselect("Status-Filter", status_vals, default=[], key="ov_status")
    only_missing=colf3.toggle("Nur ohne P-Label", value=False, key="ov_only_missing")
    proj_filter=colf4.multiselect("Projektfilter", sorted(df["Project"].unique().tolist()), default=sorted(df["Project"].unique().tolist()), key="ov_proj_filter")

    df_view=df.copy()
    if q:
        ql=q.lower(); df_view=df_view[df_view["Summary"].str.lower().str.contains(ql)|df_view["Key"].str.lower().str.contains(ql)]
    if chosen_status: df_view=df_view[df_view["Status"].isin(chosen_status)]
    if only_missing: df_view=df_view[df_view["P_Label_Aktuell"]==""]
    if proj_filter: df_view=df_view[df_view["Project"].isin(proj_filter)]

    c1,c2,c3,c4=st.columns([1,1,1,2])
    c1.metric("Tickets", len(df_view))
    c2.metric("Mit P-Label", int((df_view["P_Label_Aktuell"]!="").sum()) if not df_view.empty else 0)
    c3.metric("Ohne P-Label", int((df_view["P_Label_Aktuell"]=="").sum()) if not df_view.empty else 0)
    existing_ps=[x for x in df_view["P_Label_Aktuell"].tolist() if x]
    suggested_p=Counter(existing_ps).most_common(1)[0][0] if existing_ps else ""
    c4.write("Empf. Projektnummer: " + (f"`{suggested_p}`" if suggested_p else "‚Äî"))

    st.dataframe(df_view, use_container_width=True, hide_index=True, column_config={
        "Ticket": st.column_config.LinkColumn("Ticket √∂ffnen", display_text="Open"),
        "Project": st.column_config.TextColumn("Projekt"),
        "Key": st.column_config.TextColumn("Key"),
        "Summary": st.column_config.TextColumn("Summary"),
        "Status": st.column_config.TextColumn("Status"),
        "P_Label_Aktuell": st.column_config.TextColumn("P-Label"),
        "Alle_Labels": st.column_config.TextColumn("Alle Labels"),
    })

    st.markdown("### Schnellaktionen")
    colqa1,colqa2,colqa3=st.columns([3,2,2])
    qa_key=colqa1.selectbox("Ticket", df_view["Key"].tolist() if not df_view.empty else [], key="qa_key_select")
    qa_start=colqa2.time_input("Startzeit", value=datetime.now().time().replace(second=0, microsecond=0), key="qa_start_time")
    qa_date=colqa3.date_input("Datum", value=datetime.now().date(), key="qa_date")

    if not df_view.empty and qa_key:
        p_val=df_view.loc[df_view["Key"]==qa_key,"P_Label_Aktuell"].iloc[0]
        summ=df_view.loc[df_view["Key"]==qa_key,"Summary"].iloc[0]
        qa_desc=fill_template("", p_val, qa_key, summ, qa_date)
    else: qa_desc=""
    st.text_area("Beschreibung (Template anwendbar)", value=qa_desc, key="qa_desc", height=80)

    def quick_add(minutes:int):
        seconds=minutes*60
        if not ensure_15min(seconds): st.error("Nur Vielfaches von 15 min erlaubt."); return
        if not qa_key: st.error("Ticket w√§hlen."); return
        try:
            wid=jira.add_worklog(qa_key, to_started_iso(qa_date, qa_start), seconds, st.session_state.get("qa_desc",""))
            st.session_state.undo={"type":"worklogs","data":[(qa_key,wid)]}; st.success(f"+{minutes}m auf {qa_key} erfasst.")
        except Exception as e: st.error(f"Fehler: {e}")
    cq1,cq2,cq3=st.columns(3)
    if cq1.button("+15m", key="qa_15"): quick_add(15)
    if cq2.button("+30m", key="qa_30"): quick_add(30)
    if cq3.button("+1h",  key="qa_60"): quick_add(60)

# ----------------------------- P-Labels ----------------------------
with tab_plabel:
    st.subheader("P-Label Zuweisung (Dry-Run m√∂glich)")
    df_scope=df if st.session_state.multi_proj else (df[df["Project"]==selected_keys[0]] if selected_keys else df)
    keys_all=df_scope["Key"].tolist(); keys_without=df_scope.loc[df_scope["P_Label_Aktuell"]=="","Key"].tolist()
    dry_run_labels=st.checkbox("Nur validieren (Dry-Run)", value=True, key="labels_dryrun")
    p_number=st.text_input("Projektnummer (PXXXXXX)", value="", key="pl_p_number")
    keys_select=st.multiselect("Auswahl Tickets", keys_all, default=keys_without, key="pl_keys_select")
    def build_label_preview(target_keys,new_p):
        rows=[]
        for k in target_keys:
            r=df_scope.loc[df_scope["Key"]==k].iloc[0]
            old=[l.strip() for l in (r["Alle_Labels"].split(",") if r["Alle_Labels"] else []) if l.strip()]
            base=[l for l in old if not is_p_label(l)]
            new=base+([new_p] if new_p else [])
            rows.append({"Key":k,"Alt":", ".join(old),"Neu":", ".join(new),"√Ñndert sich?":"Ja" if set(old)!=set(new) else "Nein"})
        return pd.DataFrame(rows)
    colbb1,colbb2=st.columns(2)
    if colbb1.button("Allen in Ansicht zuweisen", key="pl_all"):
        target=keys_all
        if not p_number or not P_PATTERN.match(p_number): st.error("Ung√ºltige P-Nummer.")
        else:
            if dry_run_labels:
                st.info("Dry-Run aktiv ‚Äì Vorschau:"); st.dataframe(build_label_preview(target, p_number), use_container_width=True, hide_index=True)
            else:
                prev={}
                for k in target:
                    r=df_scope.loc[df_scope["Key"]==k].iloc[0]
                    prev[k]=[l.strip() for l in (r["Alle_Labels"].split(",") if r["Alle_Labels"] else []) if l.strip()]
                    new=[l for l in prev[k] if not is_p_label(l)]+[p_number]
                    try: jira.update_issue_labels(k,new)
                    except Exception as e: st.error(f"{k}: {e}")
                st.session_state.undo={"type":"labels","data":prev}; st.success(f"P {p_number} auf {len(target)} Ticket(s) angewandt."); refresh_after_update()
    if colbb2.button("Nur AUSWAHL zuweisen", key="pl_sel"):
        target=keys_select
        if not target: st.info("Keine Auswahl.")
        elif not p_number or not P_PATTERN.match(p_number): st.error("Ung√ºltige P-Nummer.")
        else:
            if dry_run_labels:
                st.info("Dry-Run aktiv ‚Äì Vorschau:"); st.dataframe(build_label_preview(target, p_number), use_container_width=True, hide_index=True)
            else:
                prev={}
                for k in target:
                    r=df_scope.loc[df_scope["Key"]==k].iloc[0]
                    prev[k]=[l.strip() for l in (r["Alle_Labels"].split(",") if r["Alle_Labels"] else []) if l.strip()]
                    new=[l for l in prev[k] if not is_p_label(l)]+[p_number]
                    try: jira.update_issue_labels(k,new)
                    except Exception as e: st.error(f"{k}: {e}")
                st.session_state.undo={"type":"labels","data":prev}; st.success(f"P {p_number} auf {len(target)} Ticket(s) angewandt."); refresh_after_update()

# ----------------------------- Worklog (Einzeln) -------------------
with tab_worklog:
    st.subheader("Worklog (Einzel)")
    csel1,csel2=st.columns([2,1])
    issue_choice=csel1.selectbox("Ticket (aus Liste)", df["Key"].tolist() if not df.empty else [], key="wl_key_select")
    issue_direct=csel2.text_input("Oder Key direkt (z.B. PROJ-123)", value="", key="wl_key_direct")
    use_key=issue_direct.strip() or issue_choice

    c1,c2=st.columns(2)
    work_date=c1.date_input("Datum", value=datetime.now().date(), key="wl_date")
    start_time=c2.time_input("Startzeit", value=datetime.now().time().replace(second=0, microsecond=0), key="wl_start_time")
    cc1,cc2=st.columns([1,1])
    hours=cc1.number_input("Stunden", min_value=0, max_value=24, step=1, value=0, key="wl_hours")
    minutes=cc2.selectbox("Minuten", [0,15,30,45], index=1, key="wl_minutes")

    desc=st.text_area("T√§tigkeitsbeschreibung", value="", placeholder="Was wurde gemacht?", key="wl_desc")
    if st.button("Zeit erfassen", key="wl_submit"):
        seconds=int(hours)*3600 + int(minutes)*60
        if not ensure_15min(seconds): st.error("Dauer muss Vielfaches von 15min sein und >0.")
        elif not use_key: st.error("Ticket-Key angeben.")
        else:
            try:
                wid=jira.add_worklog(use_key, to_started_iso(work_date, start_time), seconds, desc)
                st.session_state.undo={"type":"worklogs","data":[(use_key,wid)]}; st.success(f"Worklog f√ºr {use_key} erfasst.")
            except Exception as e: st.error(f"Fehler: {e}")

# ----------------------------- CSV Import --------------------------
with tab_csv:
    st.subheader("CSV-Import Zeiterfassung")
    st.caption("Spalten: **Ticketnummer;Datum;ben√∂tigte Zeit in h** | optional: **Uhrzeit, Beschreibung** | Dezimal: `.` oder `,`")
    sample="Ticketnummer;Datum;ben√∂tigte Zeit in h;Uhrzeit;Beschreibung\nPROJ-101;21.08.2025;0,25;12:30;Daily Standup\nPROJ-202;21.08.2025;1.5;09:00;Konzept & Abstimmung\n"
    st.download_button("Beispiel-CSV herunterladen", data=sample.encode("utf-8"), file_name="worklog_beispiel.csv", mime="text/csv", key="csv_sample")
    default_desc=st.text_input("Standardbeschreibung (optional, wenn CSV keine Spalte 'Beschreibung' enth√§lt)", key="csv_default_desc")
    dry_run=st.checkbox("Nur validieren (Dry-Run)", value=True, key="csv_dryrun")
    uploaded=st.file_uploader("CSV hochladen", type=["csv"], key="csv_upload")

    if uploaded is not None:
        content=uploaded.read().decode("utf-8-sig")
        try: df_csv=pd.read_csv(io.StringIO(content), sep=None, engine="python")
        except Exception: df_csv=pd.read_csv(io.StringIO(content), sep=";")
        cols={c.lower().strip(): c for c in df_csv.columns}
        def find_col(*names):
            for n in names:
                if n in cols: return cols[n]
            return None
        col_ticket=find_col("ticketnummer","ticket","issue","key")
        col_date=find_col("datum","date")
        col_hours=find_col("ben√∂tigte zeit in h","benoetigte zeit in h","hours","dauer(h)","zeit(h)")
        col_time=find_col("uhrzeit","zeit","startzeit")
        col_desc=find_col("beschreibung","description","kommentar")

        if not (col_ticket and col_date and col_hours):
            st.error("Pflichtspalten fehlen. Erwartet: Ticketnummer; Datum; ben√∂tigte Zeit in h")
        else:
            preview_rows=[]; errors=[]
            for idx,r in df_csv.iterrows():
                key=str(r[col_ticket]).strip()
                try: d=pd.to_datetime(str(r[col_date]), dayfirst=True).date()
                except Exception: errors.append(f"Zeile {idx+1}: Ung√ºltiges Datum '{r[col_date]}'"); continue
                raw_hours=str(r[col_hours]).replace(",", ".").strip()
                try: h_float=float(raw_hours)
                except Exception: errors.append(f"{key}: Ung√ºltige Stunden '{raw_hours}'"); continue
                seconds=int(round(h_float*3600))
                if seconds%900!=0: errors.append(f"{key}: {h_float}h ist kein Vielfaches von 15 min"); continue
                if col_time and not pd.isna(r[col_time]):
                    try: parsed_time=pd.to_datetime(str(r[col_time])).time()
                    except Exception: parsed_time=dtime(12,0)
                else: parsed_time=dtime(12,0)
                desc_val=""
                if col_desc and not pd.isna(r[col_desc]): desc_val=str(r[col_desc]).strip()
                elif default_desc: desc_val=default_desc
                preview_rows.append({"Ticket":key,"Datum":d.isoformat(),"Startzeit":parsed_time.strftime("%H:%M"),"Dauer (min)":seconds//60,"Beschreibung":desc_val or "(leer)"})
            st.write("**Vorschau**"); df_prev=pd.DataFrame(preview_rows); st.dataframe(df_prev, use_container_width=True, hide_index=True)
            if errors:
                with st.expander("Fehler in CSV"):
                    for e in errors: st.write("‚Ä¢ " + e)
            if preview_rows and st.button("Import starten", key="csv_import_btn"):
                if dry_run: st.info("Dry-Run aktiv ‚Äì keine Daten geschrieben.")
                else:
                    ok=0; errs=[]; created=[]; prog=st.progress(0.0, text="√úbertrage‚Ä¶")
                    for i,row in enumerate(preview_rows, start=1):
                        try:
                            started_iso=to_started_iso(pd.to_datetime(row["Datum"]).date(), datetime.strptime(row["Startzeit"], "%H:%M").time())
                            wid=jira.add_worklog(row["Ticket"], started_iso, int(row["Dauer (min)"])*60, None if row["Beschreibung"]=="(leer)" else row["Beschreibung"])
                            created.append((row["Ticket"],wid)); ok+=1
                        except Exception as e: errs.append(f"{row['Ticket']}: {e}")
                        prog.progress(i/len(preview_rows), text=f"√úbertrage‚Ä¶ ({i}/{len(preview_rows)})")
                    prog.empty(); st.success(f"Import: {ok}/{len(preview_rows)} Worklogs erstellt.")
                    if errs:
                        with st.expander("Fehlerdetails"):
                            for e in errs: st.write(e)
                    if created: st.session_state.undo={"type":"worklogs","data":created}

# ----------------------------- Reports -----------------------------
with tab_reports:
    st.subheader("Reports & Export")
    colr1,colr2=st.columns(2)
    with colr1:
        st.markdown("**Tickets ohne P-Label (aktuelle Auswahl)**")
        st.dataframe(df[df["P_Label_Aktuell"]==""][["Project","Key","Summary","Status"]], use_container_width=True, hide_index=True)
    with colr2:
        st.markdown("**Export √úbersicht**")
        st.download_button("CSV herunterladen", data=df.to_csv(index=False).encode("utf-8"), file_name="tickets_uebersicht.csv", mime="text/csv", key="rep_csv")

# ----------------------------- Timesheet --------------------------
with tab_timesheet:
    st.subheader("Wochenansicht / Timesheet")
    today=datetime.now().date()
    colts1,colts2,colts3,colts4=st.columns([2,1,1,2])
    wk_date=colts1.date_input("Woche ausw√§hlen (beliebiges Datum der Woche)", value=today, key="ts_date")
    if colts2.button("‚Äπ Vorwoche", key="ts_prev"): st.session_state.ts_date=wk_date - timedelta(days=7); st.rerun()
    if colts3.button("N√§chste Woche ‚Ä∫", key="ts_next"): st.session_state.ts_date=wk_date + timedelta(days=7); st.rerun()
    mine_only=colts4.toggle("Nur eigene Worklogs", value=True, key="ts_mine")

    week_start,_=week_bounds_from(wk_date); days=[week_start+timedelta(days=i) for i in range(7)]
    day_cols=[d.strftime("%a\n%d.%m") for d in days]; st.caption(f"Kalenderwoche: {week_start.isoformat()} bis {(week_start+timedelta(days=6)).isoformat()}")

    if st.button("Zeiten laden", key="ts_load"):
        keys=df["Key"].tolist(); logs=[]; errs=[]; prog=st.progress(0.0, text="Lade Worklogs‚Ä¶")
        for i,k in enumerate(keys, start=1):
            try:
                wl=jira.list_worklogs(k) or {}
                for w in wl.get("worklogs", []):
                    started=pd.to_datetime(w.get("started"))
                    if started.tzinfo is None: started=started.tz_localize("UTC").astimezone()
                    d0=started.date()
                    if week_start <= d0 < week_start+timedelta(days=7):
                        author=(w.get("author") or {}).get("accountId","")
                        if (not mine_only) or (author==me.get("accountId")):
                            logs.append({"Key":k,"Date":d0,"Minutes":int(w.get("timeSpentSeconds",0))//60})
            except Exception as e: errs.append(f"{k}: {e}")
            prog.progress(i/max(len(keys),1), text=f"Lade Worklogs‚Ä¶ ({i}/{len(keys)})")
        prog.empty(); st.session_state.timesheet={"logs":logs,"errors":errs,"week_start":week_start.isoformat(),"mine":mine_only}

    ts=st.session_state.get("timesheet")
    if ts and ts.get("week_start")==week_start.isoformat() and ts.get("mine")==mine_only:
        logs,errs=ts["logs"], ts["errors"]
        if errs:
            with st.expander("Fehler beim Laden"):
                for e in errs: st.write(e)
        by_issue={}
        for log in logs:
            k=log["Key"]; d0=log["Date"]; m=log["Minutes"]
            by_issue.setdefault(k,{dc:0 for dc in day_cols}); col=d0.strftime("%a\n%d.%m")
            by_issue[k][col]=by_issue[k].get(col,0)+m
        rows=[]
        for k,cols in by_issue.items():
            row={"Ticket":k}; total_min=0
            for dc in day_cols:
                mins=cols.get(dc,0); total_min+=mins; row[dc]=round(mins/60,2)
            row["Summe (h)"]=round(total_min/60,2); rows.append(row)
        df_ts=pd.DataFrame(rows) if rows else pd.DataFrame(columns=["Ticket"]+day_cols+["Summe (h)"])
        totals={"Ticket":"Œ£"}; week_total_min=0
        for dc,d in zip(day_cols,days):
            m=sum([log["Minutes"] for log in logs if log["Date"]==d]); totals[dc]=round(m/60,2); week_total_min+=m
        totals["Summe (h)"]=round(week_total_min/60,2)
        totals_df = pd.DataFrame([totals], columns=df_ts.columns if not df_ts.empty else ["Ticket"]+day_cols+["Summe (h)"])
        if df_ts.empty: df_ts = totals_df
        else: df_ts = pd.concat([df_ts, totals_df], ignore_index=True)
        cts1,cts2=st.columns([1,3]); cts1.metric("Wochensumme (h)", totals["Summe (h)"]); cts2.caption("Letzte Zeile: Tagessummen & Wochensumme")
        st.dataframe(df_ts, use_container_width=True, hide_index=True)
        st.download_button("Timesheet (CSV) herunterladen", data=df_ts.to_csv(index=False).encode("utf-8"), file_name=f"timesheet_{week_start.isoformat()}.csv", mime="text/csv", key="ts_export_csv")

# ----------------------------- Health-Check+ -----------------------
with tab_health:
    st.subheader("Health-Check+")
    ok_msgs=[]; warn_msgs=[]
    def timed(fn,*a,**kw):
        t0=time.time()
        try: res=fn(*a,**kw); return time.time()-t0, res, None
        except Exception as e: return time.time()-t0, None, e
    t_myself,_,e1=timed(jira.get_myself); ok_msgs.append(f"/myself ok ({t_myself*1000:.0f} ms)" if not e1 else f"/myself Fehler: {e1}")
    t_proj,_,e2=timed(jira.list_projects,None); ok_msgs.append(f"/project/search ok ({t_proj*1000:.0f} ms)" if not e2 else f"/project/search Fehler: {e2}")
    try:
        headers,status=jira.probe_headers(); rl=headers.get("X-RateLimit-Remaining") or headers.get("x-ratelimit-remaining") or "n/a"
        stime=headers.get("Date")
        skew="n/a"
        if stime:
            server_dt=pd.to_datetime(stime, utc=True).to_pydatetime()
            local_dt=datetime.now(timezone.utc)
            skew=f"{abs((server_dt-local_dt).total_seconds()):.0f}s"
        ok_msgs.append(f"Headers ok (Status {status}). RateLimit-Remaining: {rl}, Clock Skew ~ {skew}")
    except Exception as e: warn_msgs.append(f"Header-Check nicht m√∂glich: {e}")
    st.success("‚úî " + "\n\n‚úî ".join(ok_msgs))
    if warn_msgs: st.warning("‚ö† " + "\n\n‚ö† ".join(warn_msgs))

# ----------------------------- Undo -------------------------------
st.markdown("---")
if st.session_state.get("undo"):
    u=st.session_state["undo"]
    if u["type"]=="labels":
        if st.button("‚Ü©Ô∏è Letzte Label-√Ñnderung r√ºckg√§ngig machen", key="undo_labels"):
            prev=u["data"]; errs=[]
            for k,old in prev.items():
                try: jira.update_issue_labels(k, old)
                except Exception as e: errs.append(f"{k}: {e}")
            st.session_state.undo=None; st.success("Label-√Ñnderung r√ºckg√§ngig gemacht."); 
            fetch_issues_df.clear(); st.experimental_set_query_params(_=str(time.time())); st.rerun()
    elif u["type"]=="worklogs":
        if st.button("‚Ü©Ô∏è Letzte Worklogs r√ºckg√§ngig machen", key="undo_wl"):
            errs=[]
            for (k,wid) in u["data"]:
                try: jira.delete_worklog(k, wid)
                except Exception as e: errs.append(f"{k}/{wid}: {e}")
            st.session_state.undo=None
            if errs: st.error("Einige Worklogs konnten nicht gel√∂scht werden.")
            else: st.success("Worklogs gel√∂scht.")
